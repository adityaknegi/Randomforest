{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "from pprint import pprint\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrib1</th>\n",
       "      <th>Attrib2</th>\n",
       "      <th>Attrib3</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>large</td>\n",
       "      <td>125</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>100</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>70</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>medium</td>\n",
       "      <td>120</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>large</td>\n",
       "      <td>95</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>60</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "      <td>large</td>\n",
       "      <td>220</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>small</td>\n",
       "      <td>85</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>75</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "      <td>90</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attrib1 Attrib2  Attrib3 class\n",
       "0     yes   large      125    no\n",
       "1      no  medium      100    no\n",
       "2      no   small       70    no\n",
       "3     yes  medium      120    no\n",
       "4      no   large       95   yes\n",
       "5      no  medium       60    no\n",
       "6     yes   large      220    no\n",
       "7      no   small       85   yes\n",
       "8      no  medium       75    no\n",
       "9      no     low       90   yes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = {'A1':['young','old','old','old','old','adult','young','adult','old','young'],\n",
    "       'A2':['married','married','married','single','married','single','single','married','single','married'],\n",
    "       'A3':['small','small','big','big','big','small','small','small','small','big'],\n",
    "       'y':['No','No','Yes','No','Yes','Yes','No','Yes','Yes','Yes']}\n",
    "\n",
    "\n",
    "train = pd.DataFrame(dataset,columns=['A1','A2','A3','y'])\n",
    "train.head()\n",
    "train=pd.DataFrame({\"Attrib1\":[\"yes\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\"],\n",
    "                \"Attrib2\":[\"large\",\"medium\",\"small\",\"medium\",\"large\",\"medium\",\"large\",\"small\",\"medium\",\"low\"],\n",
    "              \"Attrib3\":[125,100,70,120,95,60,220,85,75,90],\n",
    "              \"class\":[\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"yes\"]},\n",
    "              columns=[\"Attrib1\",\"Attrib2\",\"Attrib3\",\"class\"])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self,max_depth=20,depth=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.depth = depth\n",
    "        self.count=0\n",
    "        \n",
    "    \n",
    "    def fit(self,df):\n",
    "        # validate function pending \n",
    "        return self.BuildTree(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __find_entropy(self,df):\n",
    "        # target \n",
    "        target = df.columns[-1] \n",
    "        #print(Class)\n",
    "\n",
    "        entropy = 0\n",
    "        # all varibles\n",
    "        values = df[target].unique()\n",
    "        #print(values)\n",
    "        for value in values:\n",
    "            percentage = df[target].value_counts()[value]/(len(df[target])+eps)\n",
    "            #print(percentage)\n",
    "            entropy += -percentage*np.log2(percentage+eps)\n",
    "        return entropy\n",
    "    \n",
    "    def find_mean_value(self,variables):\n",
    "        variables = np.sort(variables)\n",
    "        return [variables[0]-5]+[(a + b) / 2 for a, b in zip(variables[0:], variables[1:])]+[variables[-1]+10]\n",
    "\n",
    "    \n",
    "    def find_entropy_col_continuos(self,df,col):\n",
    "        # target value\n",
    "        target = df.columns[-1]  \n",
    "        #This gives all ouputs ('Yes' and 'No' )\n",
    "        target_variables = df[target].unique()  \n",
    "        #features value small ,medium ,large\n",
    "        pre_variables = df[col].unique()\n",
    "        variables =  self.find_mean_value(pre_variables)\n",
    "        make_entropy_point =[]\n",
    "        # make binary division \n",
    "        for variable in variables:\n",
    "            #left tree #right tree index\n",
    "            teamp_left,teamp_right = df[col]<=variable, df[col]>variable\n",
    "            entropy2 =0\n",
    "            for tree_side in (teamp_left,teamp_right):\n",
    "                entropy =0\n",
    "                total =np.sum(tree_side)\n",
    "                for target_variable in target_variables:\n",
    "                    #one class tupes # Yes class tuples or no class\n",
    "                    teamp = df[tree_side][target] == target_variable\n",
    "                    # number of elements in teamp \n",
    "                    #number of target_variable\n",
    "                    ni=np.sum(teamp)\n",
    "                    #print(\"ni {} class {}\".format(ni,target_variable))\n",
    "                    percentage = ni/(total+eps)\n",
    "                    entropy += -percentage*log(percentage+eps)\n",
    "                percentage2 = total/(len(df)+eps)\n",
    "                entropy2 += percentage2*entropy\n",
    "            make_entropy_point.append((entropy2))\n",
    "        # return entropy and split point\n",
    "        return np.min(make_entropy_point),variables[np.argmin(make_entropy_point)]\n",
    "\n",
    "\n",
    "    def find_entropy_col_catogorical(self,df,col):\n",
    "        # target value\n",
    "        target = df.columns[-1]  \n",
    "        #This gives all ouputs ('Yes' and 'No' )\n",
    "        target_variables = df[target].unique()  \n",
    "        #features value small ,medium ,large\n",
    "        variables = df[col].unique()    \n",
    "        entropy2 = 0\n",
    "        for variable in variables:\n",
    "            entropy = 0\n",
    "            for target_variable in target_variables:\n",
    "                col_f = df[col]==variable\n",
    "                ni = len(df[col][col_f][df[target] ==target_variable])\n",
    "                total = len(df[col][col_f])\n",
    "                percentage = ni/(total+eps)\n",
    "                entropy += -percentage*log(percentage+eps)\n",
    "            percentage2 = total/(len(df)+eps)\n",
    "            entropy2 += percentage2*entropy\n",
    "        return entropy2\n",
    "\n",
    "\n",
    "    def best_node(self,df):\n",
    "        information_gain = []\n",
    "        # for continuos  split  used\n",
    "        split=None\n",
    "        inf_g=0\n",
    "        for col in df.columns[:-1]:\n",
    "            if len(df[col].unique())>4 and isinstance(df[col].unique()[0],(np.int64,int,float)): \n",
    "                inf,split=self.find_entropy_col_continuos(df,col)\n",
    "                information_gain.append((inf_g,split))\n",
    "            else:\n",
    "                inf_g=self.find_entropy_col_catogorical(df,col)\n",
    "                information_gain.append((inf_g,None))\n",
    "\n",
    "            #print(key)\n",
    "            # choice col with max infomation gain\n",
    "        inf_g_x ,split_x =zip(*information_gain)\n",
    "        \n",
    "        max_inf_gain_col=np.argmin(inf_g_x)\n",
    "\n",
    "        return df.columns[:-1][max_inf_gain_col],split_x[max_inf_gain_col]\n",
    "    \n",
    "    # for continuous value \n",
    "    '''    \n",
    "    def best_split(s1,s2):\n",
    "        \n",
    "        return DecisionTree.__find_entropy(s1)'''\n",
    "    def BuildTree(self,df,tree=None): \n",
    "        #Here we build our decision tree\n",
    "        #print(self.depth)\n",
    "        #print(self.max_depth)\n",
    "        if self.depth >= self.max_depth:\n",
    "            clValue,counts = np.unique(df[df.columns[-1]],return_counts=True)\n",
    "            return clValue[np.argmax(counts)]\n",
    "\n",
    "\n",
    "        #Get attribute with maximum information gain\n",
    "        node,split= self.best_node(df)\n",
    "        #print(node)\n",
    "\n",
    "        #Get distinct value of that attribute\n",
    "        #['large' 'low' 'medium' 'large'] example\n",
    "        col_f = np.unique(df[node])\n",
    "        #print(attValue)\n",
    "\n",
    "        #dictionary for store tree   \n",
    "        if tree is None:                    \n",
    "            tree={}\n",
    "            # first node  \n",
    "            tree[node] = {}\n",
    "   \n",
    "       # recursively call to construct the tree  \n",
    "       # if int split by best mid point   # pending work   \n",
    "        #height of tree increase by 1    \n",
    "        self.depth=self.depth+1\n",
    "        #print(split)\n",
    "        \n",
    "        # for continuous value\n",
    "        if split is not None:\n",
    "            left_split = df[df[node] <= split].reset_index(drop=True)\n",
    "            right_split = df[df[node] > split].reset_index(drop=True)\n",
    "            #print(right_split)\n",
    "            for subtable in (left_split,right_split):\n",
    "                if len(subtable)==0:\n",
    "                    continue\n",
    "                \n",
    "                clValue,counts = np.unique(subtable[ df.columns[-1]],return_counts=True)\n",
    "                # check subset is pure or not \n",
    "                #print(clValue)\n",
    "\n",
    "                value=split\n",
    "                if len(counts)==1:\n",
    "                    # leaf node\n",
    "                    tree[node][value] = clValue[0]\n",
    "                else:\n",
    "                    tree[node][value]= self.BuildTree(subtable) \n",
    "                # (less then or equal 97)  or more then 97 \n",
    "                value=value+1\n",
    "                \n",
    "            \n",
    "        else:# for catogorical value\n",
    "            for value in col_f:\n",
    "                subtable = df[df[node] == value].reset_index(drop=True)\n",
    "                clValue,counts = np.unique(subtable[ df.columns[-1]],return_counts=True)\n",
    "                # check subset is pure or not \n",
    "                \n",
    "                if len(counts)==1:\n",
    "                    # leaf node\n",
    "                    tree[node][value] = clValue[0]                                                    \n",
    "                else:\n",
    "                    # recursion \n",
    "                    tree[node][value] = self.BuildTree(subtable) \n",
    "\n",
    "        return tree\n",
    "    \n",
    "    def predict(self,inst,tree):\n",
    "        #This function is used to predict for any input variable \n",
    "        # take node of tree \n",
    "        \n",
    "        for nodes in tree.keys():        \n",
    "            # values of node  'large' 'low' 'medium' 'small' \n",
    "            value = inst[nodes]\n",
    "            # for contineous value \n",
    "            # value if integer\n",
    "            \n",
    "            branches=list(tree[nodes].keys())\n",
    "            \n",
    "            if  isinstance(branches[0], (np.int64,int,np.float64)):\n",
    "                if len(branches)==1 and isinstance(tree[nodes][branches[0]],(np.int64,int,np.float64)):\n",
    "                                                               return tree[nodes][branches[0]]\n",
    "                \n",
    "                if branches[0]<=inst[nodes]:\n",
    "                    tree=tree[nodes][branches[0]]\n",
    "                else:\n",
    "                    try:\n",
    "                        tree=tree[nodes][branches[1]]\n",
    "                    except:\n",
    "                        tree=tree[nodes][branches[0]]\n",
    "            else:\n",
    "                try:\n",
    "                    value = inst[nodes]\n",
    "                    tree = tree[nodes][value]\n",
    "                    # handling mising value  example small attribute does not exit in test dataset \n",
    "                except:\n",
    "                    # find all keys\n",
    "                    All_braches =tree[nodes].keys()\n",
    "                    \n",
    "                    results=[]\n",
    "                    tree = tree[nodes]\n",
    "                    \n",
    "                    for brach_i in All_braches:\n",
    "                        #pure node\n",
    "                        sub_tree=tree[brach_i]\n",
    "                        if type(sub_tree) is dict:\n",
    "                            results.append(self.predict(inst,sub_tree))\n",
    "                        else:\n",
    "                            results.append(sub_tree)\n",
    "                        \n",
    "                    # most frequent string elemnt in list \n",
    "                    unique,pos = np.unique(results,return_inverse=True) #Finds all unique elements and their positions\n",
    "                    counts = np.bincount(pos)                     #Count the number of each unique element\n",
    "                    maxpos = counts.argmax()                      #Finds the positions of the maximum count\n",
    "                    prediction = unique[maxpos]\n",
    "                    results =[]\n",
    "                    return unique[maxpos]\n",
    "            prediction = 0\n",
    "\n",
    "            if type(tree) is dict:\n",
    "                prediction = self.predict(inst, tree)\n",
    "            else:\n",
    "                prediction = tree\n",
    "                break;                            \n",
    "\n",
    "        return prediction\n",
    "    \n",
    "    def prediction(self,inst,tree):\n",
    "        prediction =[]\n",
    "        for i in range(len(inst)):\n",
    "            prediction.append(self.predict(inst.iloc[i],tree))\n",
    "        return prediction\n",
    "    \n",
    "    def evaluate(self,X,y):\n",
    "        a=sum(X==y)\n",
    "        print('accuracy = {} %'.format(float(a/(len(X)+eps)*100)))\n",
    "        #return float(a/(len(x)+eps)*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input dataframe with lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({\"name\":[\"porcupine\",\"cat\",\"bat\",\"Whale\",\"Salamander\",\"Komodo dragon\",\"Python\",\"salmon\",\"Eagle\",\"Guppy\"],\n",
    "                   \"Body_teparature\":[\"Warm-blooded\",\"Warm-blooded\",\"Warm-blooded\",\"Warm-blooded\",\"cold-blooded\",\"cold-blooded\",\"cold-blooded\",\"cold-blooded\",\"Warm-blooded\",\"cold-blooded\"],\n",
    "                    \"gives_Birth\":[\"Yes\",\"Yes\",\"Yes\",\"Yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\"],\n",
    "                    \"Four-legged\":[\"Yes\",\"Yes\",\"no\",\"no\",\"Yes\",\"Yes\",\"no\",\"no\",\"no\",\"no\"],\n",
    "                    \"Hibernates\":[\"Yes\",\"no\",\"Yes\",\"no\",\"Yes\",\"no\",\"Yes\",\"no\",\"no\",\"no\"],\n",
    "                    \"y\":[\"Yes\",\"Yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\"]})\n",
    "\n",
    "test = pd.DataFrame({\"name\":[\"Human\",\"Pigeon\",\"Elepheant\",\"Leopard shark\",\"Turtle\",\"penguin\",\"Eel\",\"Doplpin\",\"spiny anteater\",\"Gilla monster\"],\n",
    "                   \"Body_teparature\":[\"Wa rm-blooded\",\"Warm-blooded\",\"Warm-blooded\",\"cold-blooded\",\"cold-blooded\",\"cold-blooded\",\"cold-blooded\",\"Warm-blooded\",\"Warm-blooded\",\"cold-blooded\"],\n",
    "                    \"gives_Birth\":[\"Yes\",\"no\",\"Yes\",\"Yes\",\"no\",\"no\",\"no\",\"Yes\",\"no\",\"no\"],\n",
    "                    \"Four-legged\":[\"no\",\"no\",\"Yes\",\"no\",\"Yes\",\"no\",\"no\",\"no\",\"Yes\",\"Yes\"],\n",
    "                    \"Hibernates\":[\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"Yes\",\"Yes\"],\n",
    "                    \"y\":[\"Yes\",\"no\",\"Yes\",\"no\",\"no\",\"no\",\"no\",\"Yes\",\"Yes\",\"no\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "model =DecisionTree(depth=1,max_depth=10)\n",
    "tree = model.fit(train)\n",
    "label=train[train.columns[-1]]\n",
    "predict=model.prediction(train[train.columns[:-1]],tree)\n",
    "model.evaluate(label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': {'Eagle': 'no',\n",
       "  'Guppy': 'no',\n",
       "  'Komodo dragon': 'no',\n",
       "  'Python': 'no',\n",
       "  'Salamander': 'no',\n",
       "  'Whale': 'no',\n",
       "  'bat': 'no',\n",
       "  'cat': 'Yes',\n",
       "  'porcupine': 'Yes',\n",
       "  'salmon': 'no'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randome forest tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* input dataframe with lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bootstrapped dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self,ensemble=3):\n",
    "        self.ensemble=ensemble\n",
    "        self.store_all_tree =[]\n",
    "        self.features_name= None\n",
    "        self.low =0\n",
    "        self.high=0\n",
    "        \n",
    "    def fit(self,train):\n",
    "        self.store_all_tree =[]\n",
    "        self.features_name= train.columns[:-1]\n",
    "        # number of tuples \n",
    "        self.low = train.first_valid_index() # min\n",
    "        self.high = train.last_valid_index() #max\n",
    "        for i in range(self.ensemble):\n",
    "            Decision_tree = DecisionTree()\n",
    "            # create tree with for diffrent datasets \n",
    "            tree =Decision_tree.fit(self.Bootstrapped(train))\n",
    "            # store tree\n",
    "            self.store_all_tree.append(tree)\n",
    "        return self.store_all_tree\n",
    "        \n",
    "    def Bootstrapped(self,train):\n",
    "        \n",
    "        #Return random integers from `low` (inclusive) to `high` (exclusive).\n",
    "        index =np.random.randint(low=self.low,high=self.high+1,size=10)\n",
    "        # new traing data only row with replacement all columns\n",
    "        new_train = train.iloc[index].reset_index(drop=True)\n",
    "        # number of features choice randomly m<<M(total size of features)\n",
    "\n",
    "        #name and size of features\n",
    "        size_of_col=len(self.features_name) \n",
    "        \n",
    "        # number of cloumns pick min 1 col max size_of_col(all)\n",
    "        # min 2 col\n",
    "        number_of_col =  np.random.randint(low=2,high=size_of_col+1,size=1)\n",
    "        # if number_of_col \n",
    "        # slectect number_of_col number of  columns pick randomly \n",
    "        col_val =np.random.choice(range(size_of_col), number_of_col, replace=False)\n",
    "\n",
    "        col_name =self.features_name[col_val] \n",
    "\n",
    "\n",
    "        # new dataset with m columns\n",
    "        new_train = new_train[col_name]\n",
    "        # insert label columns\n",
    "        \n",
    "        new_train[train.columns[-1]]=train[train.columns[-1]]\n",
    "\n",
    "        return new_train\n",
    "    \n",
    "    def vote(self,predict):\n",
    "        predict =np.array(predict).T\n",
    "        value=[]\n",
    "        for row in range(predict.shape[0]):\n",
    "            unique,pos = np.unique(predict[row],return_inverse=True) #Finds all unique elements and their positions\n",
    "            counts = np.bincount(pos)                     #Count the number of each unique element\n",
    "            maxpos = counts.argmax()                      #Finds the positions of the maximum count\n",
    "            value.append(unique[maxpos])\n",
    "\n",
    "        return value\n",
    "        \n",
    "    def prediction(self,x_test):\n",
    "        predict =[]\n",
    "        for i in range(self.ensemble):\n",
    "            Decision_tree=DecisionTree()\n",
    "            predict.append(Decision_tree.prediction(x_test,self.store_all_tree[i]))\n",
    "        return self.vote(predict)\n",
    "  \n",
    "    def evaluate(self,X,y):\n",
    "        a=sum(X==y)\n",
    "        print('accuracy = {} %'.format(float(a/(len(X)+eps)*100)))\n",
    "        #return float(a/(len(x)+eps)*100)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 70.0 %\n"
     ]
    }
   ],
   "source": [
    "model = RandomForest(ensemble=6)\n",
    "store_all_tree=model.fit(train)\n",
    "predict=model.prediction(train[train.columns[:-1]])\n",
    "model.evaluate(predict,train[train.columns[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of randome forest is less \n",
    "# maybe due to small dataset\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': {'Eagle': 'no',\n",
      "           'Whale': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': {'Four-legged': {'no': 'no'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "           'cat': 'no',\n",
      "           'porcupine': 'Yes'}},\n",
      " {'Hibernates': {'Yes': 'no',\n",
      "                 'no': {'Body_teparature': {'Warm-blooded': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': {'Hibernates': {'no': 'no'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "                                            'cold-blooded': 'no'}}}},\n",
      " {'name': {'Eagle': 'Yes',\n",
      "           'Guppy': 'no',\n",
      "           'Python': 'no',\n",
      "           'Salamander': 'no',\n",
      "           'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': {'name': {'Whale': 'Yes'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "           'salmon': 'no'}},\n",
      " {'name': {'Eagle': 'Yes',\n",
      "           'Komodo dragon': 'no',\n",
      "           'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': {'name': {'bat': 'no'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "           'porcupine': 'no',\n",
      "           'salmon': 'no'}},\n",
      " {'name': {'Eagle': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': {'Body_teparature': {'Warm-blooded': 'Yes'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "           'Komodo dragon': 'Yes',\n",
      "           'Python': 'no',\n",
      "           'Salamander': 'no',\n",
      "           'Whale': 'no',\n",
      "           'cat': 'no',\n",
      "           'porcupine': 'no'}},\n",
      " {'name': {'Eagle': 'no',\n",
      "           'Guppy': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': {'gives_Birth': {'yes': 'Yes'}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},\n",
      "           'Python': 'no',\n",
      "           'Salamander': 'no',\n",
      "           'Whale': 'Yes',\n",
      "           'cat': 'no',\n",
      "           'salmon': 'no'}}]\n"
     ]
    }
   ],
   "source": [
    "pprint(store_all_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
